{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fc7452-4d9c-43e0-ae5b-9f78b0ba0633",
   "metadata": {},
   "source": [
    "# Getting Bayes Done\n",
    "## Introduction\n",
    "\n",
    "So far the problems looked at in these notes have been fairly abstract and/or simple in order to show the fundemental  principles of bayesian methods. This chapter explores how to move to calculations for realistic data (type and scale of models). There is a reasonable amount that can be done via algebraic methods. However, the maths rapidly gets reasonably complicated and is only tractable for a limited number of cases (data models). Historically this is one of the things that has held back the development of Bayesian methods. Since the 1990s a range of computer based methods have been developed that from the users' point of view sidestep much of the complex mathematics. This chapter will show how these can be used.\n",
    "\n",
    "## Monte Carlo or bust\n",
    "\n",
    "The previous chapter shows that for low dimensional problems the calculations can be done by calculating the product of the prior and likelihood distributions. However, as the dimensionality (number of parameters) increases this becomes impossible[^Really] and **other methods** are required. \n",
    "\n",
    "These **other methods** that we will concentrate on are known as *Monte Carlo* methods.  These are not the only game in town. Other methods include *Variational Bayes* and the *Integrated Nested Laplace approximation (INLA)*. \n",
    "\n",
    "### A quick introduction to Monte Carlo methods\n",
    "\n",
    "Monte Carlo (MC) methods get their name from the famous casino as they depend on using random numbers. We'll take a quick look now at why/how random numbers are useful in calculations. Let's consider a definite integral:\n",
    "$$\\int_a^bf(x)dx$$. To compute the value of this we might turn to some variation of Simpon's Rule or the Trapezium rule. This would involve slicing the funtion up into strips and adding up the areas of these. For the sorts of problems you will have seen in your Mathematics lectures these will have been fine, but as the dimensionality of the problem increases these methods get extremely numerically intensive and sensitive to rounding issues. MC methods get around this via an alternative way of presenting integrals.\n",
    "\n",
    "The value of the integral above is given by the average value of $f(x)$ in the range $a \\rightarrow b$. That is:\n",
    "\n",
    "$$F=\\int^b_af(x)dx=(b-a)<f(x)>=(b-a)\\frac{1}{n}\\sum_{i=1}^{n}f(x_i)$$\n",
    "\n",
    "where $x_i$ are numbers distributed evenly in the range $a\\le x \\le b$ and $n$ is the number of values calculated. <f(x)> represents the most likely value (i.e. average) of the function - the expected value. It is sometimes written as $E(x)$.\n",
    "\n",
    "When the calculation is done using evenly distributed $x$ values the relation has the same form as Simpon's rule, but we can also take random, but uniformly distributed, trial values of $f(x)$ s in the given range - a so called Monte Carlo process. With enough samples the the result will converge to the expected value.\n",
    "\n",
    "In a more advanced course on this topic we would explore how to do this sampling. For this module will will use an established tool for doing the calculations needed to perform a Bayesian analysis.\n",
    "\n",
    "Specifically, we will use the [PyMC library](https://www.pymc.io/welcome.html) - a modern, **python based**, system allows probabalistic models to be built in a straightforward way. \n",
    "\n",
    "\n",
    "[^Really]: Really! It doesn't take long to get to a model that it would take the most powerful computers the age of the universe to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d4bce-4e0a-4153-a078-13cd4099c25a",
   "metadata": {},
   "source": [
    "## PyMC\n",
    "PyMC is one of the most popular systems for Bayesian analysis. Other examples you may come across are [Stan](https://mc-stan.org), and [Jags](https://mcmc-jags.sourceforge.io). For more routine work you may like to try [JASP](https://jasp-stats.org/) which provides an SPSS-like interface and can do frequentist as well as Bayesian analysis.\n",
    "\n",
    "It has not been possible to get PyMC installed on the lab computers this year (there is a freeze ahead of the move to Windows 11). To help get you started with the system we will use a web-based tutorial page: [PyMC demo](https://mybinder.org/v2/gh/drsimonmartin/bayesianLinearFit/HEAD?labpath=bayesian-linear-fitting.ipynb). This runs the demo on a remote machine. You may see a start screen that looks like this: ![Binder start screen](binderStart.png) \n",
    "\n",
    "Be patient it will start a Jupyter notebook that you can edit and run cells in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d779158-f77a-4dcc-81da-ff04c4ac63c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
